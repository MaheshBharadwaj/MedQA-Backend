{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain import hub\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "import warnings\n",
    "import getpass\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langgraph.prebuilt import ToolNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentRetriever:\n",
    "    def __init__(self, persist_directory):\n",
    "        self.persist_directory = persist_directory\n",
    "        self.embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\", model_kwargs={'device': 'mps'})\n",
    "        self.vector_db = Chroma(persist_directory=self.persist_directory, embedding_function=self.embeddings)\n",
    "\n",
    "    def retrieve_documents(self, query, top_k=5):\n",
    "        # Retrieve top_k relevant document chunks based on the query\n",
    "        return self.vector_db.similarity_search(query, k=top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = './chroma_db'\n",
    "retriever = DocumentRetriever(persist_directory=persist_directory)\n",
    "vector_store = retriever.vector_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nl/g_2pwbq97qnbzklz6nttyzqr0000gn/T/ipykernel_67571/1368482891.py:2: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vector_store = Chroma(embedding_function=embeddings)\n"
     ]
    }
   ],
   "source": [
    "# from langchain.vectorstores import Chroma\n",
    "# vector_store = Chroma(embedding_function=embeddings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "# import bs4\n",
    "# from langchain import hub\n",
    "# from langchain_community.document_loaders import WebBaseLoader\n",
    "# from langchain_core.documents import Document\n",
    "# from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "# from typing_extensions import List, TypedDict\n",
    "\n",
    "# # Load and chunk contents of the blog\n",
    "# loader = WebBaseLoader(\n",
    "#     web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "#     bs_kwargs=dict(\n",
    "#         parse_only=bs4.SoupStrainer(\n",
    "#             class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "#         )\n",
    "#     ),\n",
    "# )\n",
    "# docs = loader.load()\n",
    "\n",
    "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "# all_splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Index chunks\n",
    "# _ = vector_store.add_documents(documents=all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState, StateGraph\n",
    "\n",
    "graph_builder = StateGraph(MessagesState)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve(query: str):\n",
    "    \"\"\"Retrieve information related to a query.\"\"\"\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=2)\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: Hello\\n\" f\"Content: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized, retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "# Step 1: Generate an AIMessage that may include a tool-call to be sent.\n",
    "def query_or_respond(state: MessagesState):\n",
    "    \"\"\"Generate tool call for retrieval or respond.\"\"\"\n",
    "    llm_with_tools = llm.bind_tools([retrieve])\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    # MessagesState appends messages to state instead of overwriting\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# Step 2: Execute the retrieval.\n",
    "tools = ToolNode([retrieve])\n",
    "\n",
    "\n",
    "# Step 3: Generate a response using the retrieved content.\n",
    "def generate(state: MessagesState):\n",
    "    \"\"\"Generate answer.\"\"\"\n",
    "    # Get generated ToolMessages\n",
    "    recent_tool_messages = []\n",
    "    for message in reversed(state[\"messages\"]):\n",
    "        if message.type == \"tool\":\n",
    "            recent_tool_messages.append(message)\n",
    "        else:\n",
    "            break\n",
    "    tool_messages = recent_tool_messages[::-1]\n",
    "\n",
    "    # Format into prompt\n",
    "    docs_content = \"\\n\\n\".join(doc.content for doc in tool_messages)\n",
    "    system_message_content = (\n",
    "        \"You are an Medical assistant for question-answering tasks. \"\n",
    "        \"Use the following pieces of retrieved context to answer \"\n",
    "        \"the question. If you don't know the answer, say that you \"\n",
    "        \"don't know. Use three sentences maximum and keep the \"\n",
    "        \"answer concise.\"\n",
    "        \"\\n\\n\"\n",
    "        f\"{docs_content}\"\n",
    "    )\n",
    "    conversation_messages = [\n",
    "        message\n",
    "        for message in state[\"messages\"]\n",
    "        if message.type in (\"human\", \"system\")\n",
    "        or (message.type == \"ai\" and not message.tool_calls)\n",
    "    ]\n",
    "    prompt = [SystemMessage(system_message_content)] + conversation_messages\n",
    "\n",
    "    # Run\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "graph_builder.add_node(query_or_respond)\n",
    "graph_builder.add_node(tools)\n",
    "graph_builder.add_node(generate)\n",
    "\n",
    "graph_builder.set_entry_point(\"query_or_respond\")\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"query_or_respond\",\n",
    "    tools_condition,\n",
    "    {END: END, \"tools\": \"tools\"},\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"generate\")\n",
    "graph_builder.add_edge(\"generate\", END)\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "input_message = \"Hello\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Can you tell me if a patient with cancer should undergo inpatient or outpatient surgery?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (call_H9B3vRFINwFEK3mkSDgk6ROX)\n",
      " Call ID: call_H9B3vRFINwFEK3mkSDgk6ROX\n",
      "  Args:\n",
      "    query: inpatient vs outpatient surgery for cancer patients\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: Hello\n",
      "Content: General Theme – What determines if an outpatient surgery should be done at KOP versus main OR? This is not always black and white and will require clinical judgement. The following guidelines aim to set some expectations but does not fill all the holes. In general, the thought process is that if the MD feels the following, surgery may need to move to the main hospital:\n",
      "patient will be very high risk for admission, patient should be done in the main operating room. This is also dependent on the type of surgery and anesthesia plan (not just patient comorbidities)\n",
      "patient will require more invasive monitoring for safe anesthesia (i.e. arterial line, central line), patient should be done in the main operating room\n",
      "patient is at high risk for serious morbidity or complication that, if occurs, KOP does not have the resources to manage (i.e. cath lab, stroke team, labor & delivery/intraoperative fetal monitoring)\n",
      "\n",
      "Source: Hello\n",
      "Content: 7\n",
      "Patient selection in ambulatory surgery\n",
      "John A. Hodgson, MD, Associate Professora,\n",
      "Kyle L. Cyr, MD, Assistant Professora,\n",
      "BobbieJean Sweitzer, MD, FACP, SAMBA-F, FASA, Professorb, *\n",
      "a Walter Reed National Military Medical Center and Uniformed Services University, 8901 Wisconsin Avenue,\n",
      "Bethesda, MD, 20889, United States\n",
      "b Medical Education, University of Virginia, Systems Director, Preoperative Medicine, Inova Health, 3300\n",
      "Gallows Road, Falls Church, VA, 22042, United States\n",
      "Keywords:\n",
      "ambulatory\n",
      "anesthesia\n",
      "surgery\n",
      "outpatient\n",
      "ofﬁce-based\n",
      "preoperative\n",
      "comorbidities\n",
      "ambulatory surgicenters\n",
      "Patient selection is important for ambulatory surgical practices.\n",
      "Proper patient selection for ambulatory practices will optimize\n",
      "resources and lead to increased patient and provider satisfaction.\n",
      "As the number and complexity of procedures in ambulatory sur-\n",
      "gical centers increase, it is important to ensure that patients are\n",
      "best cared for in facilities that can provide appropriate levels of\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The decision for a patient with cancer to undergo inpatient or outpatient surgery depends on various factors, including the patient's overall risk for complications, the type of surgery being performed, and the anesthesia plan. If the patient is considered high risk for admission or requires more invasive monitoring, they should undergo surgery in the main operating room. Ultimately, clinical judgment is essential in determining the appropriate setting.\n"
     ]
    }
   ],
   "source": [
    "input_message = \"Can you tell me if a patient with cancer should undergo inpatient or outpatient surgery?\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Can you look up some common ways of doing it?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (call_xs89WtZCfhhtqdWcKMvtcPAN)\n",
      " Call ID: call_xs89WtZCfhhtqdWcKMvtcPAN\n",
      "  Args:\n",
      "    query: common ways of doing it\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: Hello\n",
      "Content: within a relatively short period. Patients with multi-\n",
      "ple comorbidities, or who are frail, severely depressed\n",
      "or have poor nutritional status may have the most to\n",
      "gain from a multimodal prehabilitation program\n",
      "[18]. Typical prehabilitation programs tend to use a\n",
      "multimodal approach incorporating two or more\n",
      "interventions. Patient and family education allows\n",
      "for clear expectation setting, encourages patient par-\n",
      "ticipation and engagement in their recovery, reduces\n",
      "anxiety, and increases patient satisfaction [19]. Most\n",
      "studies on psychological preparation for surgery are\n",
      "limited by their heterogeneity and only provide low-\n",
      "quality evidence [20,21].\n",
      "OPTIMIZATION OF COMORBID\n",
      "CONDITIONS\n",
      "Unlike prehabilitation which requires lifestyle\n",
      "changes made by the patient, optimization refers\n",
      "to medical interventions by the clinician to bring\n",
      "patient comorbidities to an optimal state before\n",
      "surgery.\n",
      "Ideally, this process begins at the time of\n",
      "scheduling. The goal is to achieve the best possible\n",
      "\n",
      "Source: Hello\n",
      "Content: optimization.13 Developing and implementing pro-\n",
      "tocols (or clinical pathways) for patient selection and \n",
      "prehabilitation would further enhance patient safety \n",
      "and efficiency. 15 This requires a multidisciplinary \n",
      "approach in which the anesthesiologist should take a \n",
      "lead in collaborating with the surgeons and the peri-\n",
      "operative nurses.15,132 Conundrums likely to be faced \n",
      "by ambulatory anesthesiologists in the near future \n",
      "include caring for recently hospitalized patients, \n",
      "patients using medical or recreational marijuana, \n",
      "patients with learning disabilities and or psychiatric \n",
      "illnesses, and patients with post–coronavirus disease \n",
      "2019 (COVID-19) syndrome. While none of these con-\n",
      "ditions preclude outpatient surgery, these patients \n",
      "may require specific preparation and considerations \n",
      "before and on the day of surgery. In the future, as \n",
      "more patients and surgical procedures are moved \n",
      "from inpatient to outpatient facilities, it is advis-\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I don't know.\n"
     ]
    }
   ],
   "source": [
    "input_message = \"Can you look up some common ways of doing it?\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "med277project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
